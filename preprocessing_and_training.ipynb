{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['url', 'label', 'label_binary'], dtype='object')\n",
      "                                                 url       label  label_binary\n",
      "0                                   br-icloud.com.br    phishing             0\n",
      "1                mp3raid.com/music/krizz_kaliko.html      benign             1\n",
      "2                    bopsecrets.org/rexroth/cr/1.htm      benign             1\n",
      "3  http://www.garage-pirenne.be/index.php?option=...  defacement             0\n",
      "4  http://adventure-nicaragua.net/index.php?optio...  defacement             0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghifa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ghifa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.67      0.78     55401\n",
      "           1       0.94      0.99      0.96    286037\n",
      "\n",
      "    accuracy                           0.94    341438\n",
      "   macro avg       0.93      0.83      0.87    341438\n",
      "weighted avg       0.94      0.94      0.93    341438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import tldextract\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "file_path1 = r'data\\dt\\url.csv'\n",
    "file_path2 = r'data\\dt\\urls.csv'\n",
    "\n",
    "df1 = pd.read_csv(file_path1)\n",
    "df2 = pd.read_csv(file_path2)\n",
    "\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "print(df.columns)\n",
    "print(df.head())\n",
    "\n",
    "def extract_features(url):\n",
    "    features = {}\n",
    "    ext = tldextract.extract(url)\n",
    "    features['domain'] = ext.domain\n",
    "    features['subdomain'] = ext.subdomain\n",
    "    features['suffix'] = ext.suffix\n",
    "    features['has_ip'] = bool(re.search(r'\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b', url))\n",
    "    suspicious_tlds = ['top', 'info', 'xyzzy']\n",
    "    features['suspicious_tld'] = ext.suffix in suspicious_tlds\n",
    "    return features\n",
    "\n",
    "features = df['url'].apply(extract_features)\n",
    "features_df = pd.DataFrame(list(features))\n",
    "\n",
    "if 'label_binary' in df.columns:\n",
    "    features_df['label'] = df['label_binary']\n",
    "else:\n",
    "    raise KeyError(\"'label_binary' column is missing from the DataFrame\")\n",
    "\n",
    "top_domains = features_df['domain'].value_counts().nlargest(1000).index\n",
    "features_df['domain'] = features_df['domain'].apply(lambda x: x if x in top_domains else 'other')\n",
    "\n",
    "top_subdomains = features_df['subdomain'].value_counts().nlargest(1000).index\n",
    "features_df['subdomain'] = features_df['subdomain'].apply(lambda x: x if x in top_subdomains else 'other')\n",
    "\n",
    "top_suffixes = features_df['suffix'].value_counts().nlargest(100).index\n",
    "features_df['suffix'] = features_df['suffix'].apply(lambda x: x if x in top_suffixes else 'other')\n",
    "\n",
    "hasher = FeatureHasher(input_type='string', n_features=1024)\n",
    "hashed_features = hasher.transform(features_df[['domain', 'subdomain', 'suffix']].astype(str).values)\n",
    "hashed_df = pd.DataFrame.sparse.from_spmatrix(hashed_features, columns=[f'hash_{i}' for i in range(hashed_features.shape[1])])\n",
    "\n",
    "features_df = pd.concat([features_df.drop(columns=['domain', 'subdomain', 'suffix']), hashed_df], axis=1)\n",
    "\n",
    "X = features_df.drop(columns=['label'])\n",
    "y = features_df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the model\n",
    "with open(r'model.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc859094040ce9c5960c2858404c4c3c1af21fdf09e3ff8d767e1b7a871c05b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
